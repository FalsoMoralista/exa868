{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "98f8f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "id": "7edbd1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(5, 4)\n",
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, input_shape):\n",
    "      self.input_shape = input_shape\n",
    "      self.bias = 1      \n",
    "      self.bias_weight = np.random.uniform(low=-1, high=1.0, size=1)\n",
    "      self.weight_matrix = np.random.uniform(low=-1, high=1.0, size=self.input_shape)\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "      return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def threshold(self, x):\n",
    "      if x >= 0:\n",
    "        return 1\n",
    "      else:\n",
    "        return -1\n",
    "    \n",
    "    def dot_product(self, input_pattern):\n",
    "      return np.dot(input_pattern, self.weight_matrix)\n",
    "        \n",
    "    def activate(self, x, activation):\n",
    "      if activation == 'linear':\n",
    "        return x\n",
    "      if activation == 'sigmoid':\n",
    "        return self.sigmoid(x)\n",
    "      if activation == 'tanh':\n",
    "        return np.tanh(x)\n",
    "      if activation == 'threshold':\n",
    "        return self.threshold(x)\n",
    "\n",
    "class Layer():\n",
    "  def __init__(self, input_shape): \n",
    "    self.neurons = []\n",
    "    self.input_shape = input_shape\n",
    "    for i in range(input_shape[0]):\n",
    "      self.neurons.append(Neuron(input_shape=input_shape[1]))\n",
    "        \n",
    "class MultiLayerPerceptron: \n",
    "  \n",
    "  def build_layers(self, input_shape):\n",
    "    for i in range(0, len(input_shape)-1):\n",
    "      self.layers.append(Layer(input_shape=(input_shape[i+1],input_shape[i])))\n",
    "  \n",
    "  '''\n",
    "      input_shape: Array or tuple with the corresponding\n",
    "      number of neurons per layer.\n",
    "      \n",
    "  '''\n",
    "  def __init__(self, input_shape):\n",
    "    self.layers = [] # to_do replace layers by weight matrix\n",
    "    self.build_layers(input_shape)\n",
    "    self.weight_matrix = [None] * len(input_shape)\n",
    "    self.weight_matrix[0] = np.random.uniform(low=-1, high=1.0, size=(input_shape[0]))\n",
    "    \n",
    "    # nao bolir\n",
    "    for i in range(0, len(input_shape)-1):\n",
    "      self.weight_matrix[i+1] = np.random.uniform(low=-1, high=1.0, size=(input_shape[i+1],input_shape[i])) # one column added to the corresponding bias weight\n",
    "    for i in range(len(self.weight_matrix)):\n",
    "      print(self.weight_matrix[i].shape)\n",
    "    self.input_shape = input_shape\n",
    "\n",
    "  def derivative(self, x, activation):\n",
    "    if activation == 'tanh':\n",
    "      return (1 - (np.tanh(x)**2))\n",
    "    \n",
    "    \n",
    "  def forward_pass(self, input_pattern):\n",
    "    first_out = []\n",
    "    inact_out = []\n",
    "    for neuron in self.layers[0].neurons:\n",
    "      dot = neuron.dot_product(input_pattern) # neuron.bias * neuron.bias_weight[0] +\n",
    "      induced_local_field = neuron.activate(dot, 'tanh')\n",
    "      first_out.append(induced_local_field)\n",
    "      inact_out.append(dot)\n",
    "    output_by_layer = [first_out]\n",
    "    inactivated_outputs = [inact_out]\n",
    "    for i in range(len(self.layers)-1):\n",
    "      layer_out = []\n",
    "      inact_out = []\n",
    "      for neuron in self.layers[i+1].neurons:\n",
    "        dot = neuron.dot_product(inactivated_outputs[i]) # neuron.bias * neuron.bias_weight[0] +\n",
    "        inact_out.append(dot)\n",
    "        dot = neuron.dot_product(output_by_layer[i]) # neuron.bias * neuron.bias_weight[0] +\n",
    "        induced_local_field = neuron.activate(dot, 'tanh')\n",
    "        layer_out.append(induced_local_field)\n",
    "      output_by_layer.append(layer_out)    \n",
    "      inactivated_outputs.append(inact_out)\n",
    "    return output_by_layer, inactivated_outputs \n",
    "  \n",
    "  def backpropagate(self, output_by_layer, inact_output_by_layer, input_pattern, desired_output):\n",
    "    error = []\n",
    "    lr = 0.01 # test \n",
    "    deltas = []\n",
    "    for l in reversed(range(len(self.layers))):\n",
    "      # If it is an output layer:\n",
    "      if (l+1) == len(self.layers):\n",
    "        print('Output layer')\n",
    "        for j in range(len(output_by_layer[l])):\n",
    "          neuron_output = output_by_layer[l][j]\n",
    "          error = (desired_output[j] - neuron_output) # (error**2)/2 \n",
    "          print('Error by neuron:', error, 'OUTPUT_LAYER')\n",
    "          # Update bias weight:\n",
    "          current_neuron = self.layers[l].neurons[j] # truly neuron correspondent to this output?\n",
    "          local_field_neuron_j = inact_output_by_layer[l][j]\n",
    "          delta = error * self.derivative(local_field_neuron_j, 'tanh')\n",
    "          deltas.append(delta)\n",
    "          current_neuron.bias_weight = current_neuron.bias_weight + (lr * delta)\n",
    "          # Update weights to previous layer neurons:\n",
    "          for i in range(len(current_neuron.weight_matrix)):\n",
    "            y_sub_i = output_by_layer[l-1][i]\n",
    "            nabla_sub_ji = lr * delta * y_sub_i # nabla\n",
    "            current_neuron.weight_matrix[i] = current_neuron.weight_matrix[i] + nabla_sub_ji\n",
    "          # delta_weight = eta * delta_j(n) * y_i(n)\n",
    "          # where delta_j(n) equals to: e_j(n) * fi'_j(v_j(n)) which corresponds to the local gradient\n",
    "          # where y_i(n) equals to fi_i(v_i(n)) which corresponds to the input signal of neuron j           \n",
    "      else:\n",
    "        print('Hidden layer')\n",
    "        # TODO: aggregate delta * weight (for each output neuron of the next (output) layer)\n",
    "        for j in range(len(output_by_layer[l])): \n",
    "          accumulated_delta_k = 0\n",
    "          # Code below assumes that the (next) layer l+1 is the output layer therefore should only work for 2 layers networks at first.\n",
    "          # Despite that, making it generalizable should be straightforward since implies \n",
    "          # only testing whether layer 'l+1' is an output node or not (TO-DO).\n",
    "          for k in range(len(output_by_layer[l+1])):  # For each neuron k (if output layer) do:\n",
    "            neuron_output = output_by_layer[l+1][k]\n",
    "            error = (desired_output[k] - neuron_output)\n",
    "            local_field_neuron_k = inact_output_by_layer[l+1][k]\n",
    "            delta_sub_k = error * self.derivative(local_field_neuron_k, 'tanh') # Get the weighted sum of the local gradients by the\n",
    "            w_sub_kj = self.layers[l+1].neurons[k].weight_matrix[j] # corresponding weight connections between neurons j and k.\n",
    "            accumulated_delta_k += delta_sub_k * w_sub_kj  # Propagate them back as error for updating the weights on neuron j.\n",
    "          # Weight Update Rule:\n",
    "          local_field_neuron_j = inact_output_by_layer[l][j]\n",
    "          fi_sub_j = self.derivative(local_field_neuron_j, 'tanh')\n",
    "          delta_j  =  fi_sub_j * accumulated_delta_k\n",
    "          # Update weights:\n",
    "          neuron_j = self.layers[l].neurons[j]\n",
    "          for i in range(len(neuron_j.weight_matrix)):\n",
    "            neuron_j.weight_matrix[i] = neuron_j.weight_matrix[i] + lr * (delta_j * input_pattern[i]) \n",
    "          # Update bias:\n",
    "          neuron_j.bias_weight += delta_j * lr\n",
    "        \n",
    "  def train(X, y, self, learning_rate, error):\n",
    "    prev_mse = 999999999\n",
    "    current_mse  = 0\n",
    "    epochs = 0 \n",
    "    for (X,y) in zip(X,y):\n",
    "      outputs = self.forward_pass(X)\n",
    "      \n",
    "      \n",
    "nn = MultiLayerPerceptron(input_shape=[4,5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "4fe72c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44089024149141887\n",
      "0.025968679754366786\n",
      "0.36714037496661556\n",
      "-0.1339619769057796\n"
     ]
    }
   ],
   "source": [
    "for w in nn.layers[0].neurons[0].weight_matrix:\n",
    "  print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2017,
   "id": "a9dd7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Pattern: [ 0.2820512  -0.12820512 -0.6666667  -0.974359  ] | | Label: [0, 0, 1]\n",
      "Resulting Outputs:\n",
      "[0.7852367670990879, -0.5153720282196315, 0.08652753109353586, 0.45180664753392447, -0.2395268600584649]\n",
      "[0.0010951402662205709, 0.004581361034432474, 0.8875656329446858]\n",
      "Backpropagation Result:\n",
      "Output layer\n",
      "Error by neuron: -0.0010951402662205709 OUTPUT_LAYER\n",
      "Error by neuron: -0.004581361034432474 OUTPUT_LAYER\n",
      "Error by neuron: 0.11243436705531418 OUTPUT_LAYER\n",
      "Hidden layer\n"
     ]
    }
   ],
   "source": [
    "X = data[0]['Iris-setosa'][0]\n",
    "y = [0,0,1]\n",
    "print('Input Pattern:', X, '| | Label:', y)\n",
    "\n",
    "outputs, inactivated_outputs = nn.forward_pass(X)\n",
    "print('Resulting Outputs:')\n",
    "for output in outputs:\n",
    "  print(output)\n",
    "\n",
    "#print('Inactivated Outputs:')\n",
    "#for output in inactivated_outputs:\n",
    "#  print(output)\n",
    "print('Backpropagation Result:')\n",
    "nn.backpropagate(outputs, inactivated_outputs, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "bcc3daf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Pattern: [ 0.2820512  -0.12820512 -0.6666667  -0.974359  ] | | Label: [0, 0, 1]\n",
      "Resulting Outputs:\n",
      "[0.00679099940227588, -0.28274649204076857, -0.40729772373546497, 0.5656305702283385, 0.41756191216861455]\n",
      "[-0.7064888533882302, -0.18336722543214204, 0.32402345206121086]\n",
      "Backpropagation Result:\n",
      "Output layer\n",
      "Error by neuron: 0.7064888533882302 OUTPUT_LAYER\n",
      "Error by neuron: 0.18336722543214204 OUTPUT_LAYER\n",
      "Error by neuron: 0.6759765479387891 OUTPUT_LAYER\n",
      "Hidden layer\n"
     ]
    }
   ],
   "source": [
    "X = data[0]['Iris-setosa'][0]\n",
    "y = [0,0,1]\n",
    "print('Input Pattern:', X, '| | Label:', y)\n",
    "\n",
    "outputs, inactivated_outputs = nn.forward_pass(X)\n",
    "print('Resulting Outputs:')\n",
    "for output in outputs:\n",
    "  print(output)\n",
    "\n",
    "#print('Inactivated Outputs:')\n",
    "#for output in inactivated_outputs:\n",
    "#  print(output)\n",
    "print('Backpropagation Result:')\n",
    "nn.backpropagate(outputs, inactivated_outputs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "8e013151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "14b305f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Layer: [ 0.2820512  -0.12820512 -0.6666667  -0.974359  ]\n",
      "[0.22903411 0.48616465 0.74657338 0.33078536 0.23179094]\n",
      "[-0.3170529   0.24037535 -0.61234509]\n"
     ]
    }
   ],
   "source": [
    "nn.weight_matrix[1][0] = nn.layers[0].neurons[0].weight_matrix\n",
    "nn.weight_matrix[1][1] = nn.layers[0].neurons[1].weight_matrix\n",
    "nn.weight_matrix[1][2] = nn.layers[0].neurons[2].weight_matrix\n",
    "nn.weight_matrix[1][3] = nn.layers[0].neurons[3].weight_matrix\n",
    "nn.weight_matrix[1][4] = nn.layers[0].neurons[4].weight_matrix\n",
    "\n",
    "nn.weight_matrix[2][0] = nn.layers[1].neurons[0].weight_matrix\n",
    "nn.weight_matrix[2][1] = nn.layers[1].neurons[1].weight_matrix\n",
    "nn.weight_matrix[2][2] = nn.layers[1].neurons[2].weight_matrix\n",
    "\n",
    "test_neuron = Neuron(input_shape=1)\n",
    "# forward pass function:\n",
    "print('Input Layer:', X)\n",
    "result = np.dot(X, np.transpose(nn.weight_matrix[1])) \n",
    "for i in range(len(result)):\n",
    "  result[i] = test_neuron.activate(result[i], 'tanh')\n",
    "print(result)\n",
    "for i in range(2,len(nn.weight_matrix)):\n",
    "  result = np.dot(result, np.transpose(nn.weight_matrix[i]))\n",
    "  for j in range(len(result)):\n",
    "    result[j] = test_neuron.activate(result[j], 'tanh')\n",
    "  print(result)\n",
    "  \n",
    "#outputs, inactivated_ones = nn.forward_pass(nn.weight_matrix[0])\n",
    "#print()\n",
    "#print(inactivated_ones[0])\n",
    "#print(inactivated_ones[1])\n",
    "#print()\n",
    "#print(outputs[0])\n",
    "#print(outputs[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "9f41fe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.67928981,  0.40334196, -0.80242887,  0.55023899,  0.20787583])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.layers[1].neurons[0].weight_matrix\n",
    "\n",
    "add = 0\n",
    "add += "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "58ec8c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, inactivated_ones = nn.forward_pass(nn.weight_matrix[0])\n",
    "#nn.backpropagate(outputs, [1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "cf104fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.9488529285876995, 0.7161474163933556, 0.9391050398666555]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "832c2b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in reversed(range(len(nn.layers))):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a7bf14ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "print(len(nn.layers[1].neurons))\n",
    "print(nn.layers[1].neurons[0].weight_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a35a1879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Layer: [ 0.26779003 -0.50358615  0.71649754  0.01961462]\n",
      "[-0.19018648  0.50754469  0.36764628  0.61928295 -0.49748821]\n",
      "[ 0.01628897 -0.38813352 -0.55546591]\n",
      "\n",
      "[-0.19253064122889776, 0.5594169350311841, 0.3856987876472758, 0.7238411246338803, -0.5459626807409129]\n",
      "[-0.003956903094544939, -0.47267116986101954, -0.708851870955559]\n",
      "\n",
      "[-0.19018648081251277, 0.5075446945177944, 0.36764627953494916, 0.6192829471613975, -0.4974882126298704]\n",
      "[0.016288970116370247, -0.3881335179639093, -0.5554659123513682]\n"
     ]
    }
   ],
   "source": [
    "nn.weight_matrix[1][0] = nn.layers[0].neurons[0].weight_matrix\n",
    "nn.weight_matrix[1][1] = nn.layers[0].neurons[1].weight_matrix\n",
    "nn.weight_matrix[1][2] = nn.layers[0].neurons[2].weight_matrix\n",
    "nn.weight_matrix[1][3] = nn.layers[0].neurons[3].weight_matrix\n",
    "nn.weight_matrix[1][4] = nn.layers[0].neurons[4].weight_matrix\n",
    "\n",
    "nn.weight_matrix[2][0] = nn.layers[1].neurons[0].weight_matrix\n",
    "nn.weight_matrix[2][1] = nn.layers[1].neurons[1].weight_matrix\n",
    "nn.weight_matrix[2][2] = nn.layers[1].neurons[2].weight_matrix\n",
    "\n",
    "test_neuron = Neuron(input_shape=1)\n",
    "# forward pass function:\n",
    "print('Input Layer:', nn.weight_matrix[0])\n",
    "result = np.dot(nn.weight_matrix[0], np.transpose(nn.weight_matrix[1])) \n",
    "for i in range(len(result)):\n",
    "  result[i] = test_neuron.activate(result[i], 'tanh')\n",
    "print(result)\n",
    "for i in range(2,len(nn.weight_matrix)):\n",
    "  result = np.dot(result, np.transpose(nn.weight_matrix[i]))\n",
    "  for j in range(len(result)):\n",
    "    result[j] = test_neuron.activate(result[j], 'tanh')\n",
    "  print(result)\n",
    "  \n",
    "outputs, inactivated_ones = nn.forward_pass(nn.weight_matrix[0])\n",
    "print()\n",
    "print(inactivated_ones[0])\n",
    "print(inactivated_ones[1])\n",
    "print()\n",
    "print(outputs[0])\n",
    "print(outputs[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "591d12b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias: 1\n",
      "Bias weight: [0.2156437]\n",
      "Weight Matrix: [0.5432315  0.72287656 0.39845131 0.0565957 ]\n",
      "Bias: 1\n",
      "Bias weight: [-0.2189839]\n",
      "Weight Matrix: [ 0.07349027 -0.65203745 -0.82727309  0.78663128]\n",
      "Bias: 1\n",
      "Bias weight: [-0.43861804]\n",
      "Weight Matrix: [-0.30502887  0.14722073  0.29790061 -0.31612596]\n",
      "Bias: 1\n",
      "Bias weight: [-0.50748182]\n",
      "Weight Matrix: [ 0.83976118  0.53790922 -0.15006508  0.07148819]\n",
      "Bias: 1\n",
      "Bias weight: [-0.88297892]\n",
      "Weight Matrix: [ 0.39303369  0.01601854  0.62880469 -0.94715056]\n",
      "\n",
      "Bias: 1\n",
      "Bias weight: [-0.56159472]\n",
      "Weight Matrix: [ 0.21169708  0.31904389  0.11594083  0.7189823  -0.95576425]\n",
      "Bias: 1\n",
      "Bias weight: [0.8916593]\n",
      "Weight Matrix: [-0.03179963  0.99742531 -0.89876418  0.13781569 -0.86104123]\n"
     ]
    }
   ],
   "source": [
    "for neuron in nn.layers[0].neurons:\n",
    "  print('Bias:' , neuron.bias)\n",
    "  print('Bias weight:', neuron.bias_weight)\n",
    "  print('Weight Matrix:', neuron.weight_matrix)\n",
    "\n",
    "print()  \n",
    "for neuron in nn.layers[1].neurons:\n",
    "\n",
    "  print('Bias:' , neuron.bias)\n",
    "\n",
    "  print('Bias weight:', neuron.bias_weight)\n",
    "\n",
    "  print('Weight Matrix:', neuron.weight_matrix)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9b7cc8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93687414])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.layers[0].neurons[0].bias_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b6d4e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00111759,  0.67598335, -0.87129364, -0.48858705],\n",
       "       [-0.61768803,  0.70156015, -0.88117519, -0.3185993 ],\n",
       "       [-0.53684066, -0.04649365, -0.19035894, -0.03218577],\n",
       "       [ 0.12676204, -0.18736079,  0.63508442, -0.68610225],\n",
       "       [-0.83814944,  0.90275327, -0.13131897, -0.01142184]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weight_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "51e9fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assembly_dataset():\n",
    "  f = open(\"iris.data\", \"r\")\n",
    "  data_x = []\n",
    "  data_y = []\n",
    "  for line in f:\n",
    "    if len(line) != 1:\n",
    "      data = line.replace('\\n', '')\n",
    "      t = data.split(',')\n",
    "      data_y.append(t.pop(4))\n",
    "      data_x.append(np.array(t,dtype=np.float32))\n",
    "  return data_x, data_y\n",
    "\n",
    "def normalize_row(row, max_val, min_val):\n",
    "  for i in range(len(row)):\n",
    "    row[i] = (2 * ((row[i] - min_val)/(max_val - min_val))) - 1 \n",
    "\n",
    "def find_max_min(features):\n",
    "  max_val = features[0][0]\n",
    "  min_val = features[0][0]\n",
    "  for i in range(len(features)):\n",
    "    max_test = features[i][np.argmax(features[i])] \n",
    "    if max_test > max_val:\n",
    "      max_val = max_test\n",
    "      \n",
    "    min_test = features[i][np.argmin(features[i])] \n",
    "    if min_test < min_val:\n",
    "      min_val = min_test\n",
    "  return max_val, min_val\n",
    "    \n",
    "def feature_normalization(features):\n",
    "  max_val, min_val = find_max_min(features)\n",
    "  for feature in features:\n",
    "    normalize_row(feature, max_val, min_val)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5edf95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "25f935ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-virginica': [array([ 0.5897436 , -0.17948717,  0.5128205 , -0.38461536], dtype=float32), array([ 0.46153855, -0.3333333 ,  0.2820512 , -0.53846157], dtype=float32), array([ 0.7948718 , -0.25641024,  0.48717952, -0.48717952], dtype=float32), array([ 0.5897436 , -0.28205127,  0.4102564 , -0.5641026 ], dtype=float32), array([ 0.64102566, -0.25641024,  0.46153855, -0.46153843], dtype=float32), array([ 0.92307687, -0.25641024,  0.6666666 , -0.48717952], dtype=float32), array([ 0.23076928, -0.38461536,  0.12820518, -0.5897436 ], dtype=float32), array([ 0.84615386, -0.28205127,  0.5897436 , -0.5641026 ], dtype=float32), array([ 0.6923076 , -0.38461536,  0.46153855, -0.5641026 ], dtype=float32), array([ 0.8205128 , -0.1025641 ,  0.53846145, -0.38461536], dtype=float32), array([ 0.64102566, -0.2051282 ,  0.2820512 , -0.51282054], dtype=float32), array([ 0.6153846 , -0.3333333 ,  0.33333337, -0.53846157], dtype=float32), array([ 0.7179488 , -0.25641024,  0.38461542, -0.48717952], dtype=float32), array([ 0.43589735, -0.38461536,  0.25641024, -0.51282054], dtype=float32), array([ 0.46153855, -0.3076923 ,  0.2820512 , -0.4102564 ], dtype=float32), array([ 0.6153846 , -0.2051282 ,  0.33333337, -0.4358974 ], dtype=float32), array([ 0.64102566, -0.25641024,  0.38461542, -0.5641026 ], dtype=float32), array([ 0.94871783, -0.05128205,  0.6923076 , -0.46153843], dtype=float32), array([ 0.94871783, -0.3589744 ,  0.74358976, -0.4358974 ], dtype=float32), array([ 0.5128205 , -0.46153843,  0.25641024, -0.64102566], dtype=float32), array([ 0.74358976, -0.2051282 ,  0.43589735, -0.4358974 ], dtype=float32), array([ 0.4102564 , -0.3076923 ,  0.23076928, -0.51282054], dtype=float32), array([ 0.94871783, -0.3076923 ,  0.6923076 , -0.51282054], dtype=float32), array([ 0.5897436 , -0.3333333 ,  0.23076928, -0.5641026 ], dtype=float32), array([ 0.6923076 , -0.17948717,  0.43589735, -0.48717952], dtype=float32), array([ 0.8205128, -0.2051282,  0.5128205, -0.5641026], dtype=float32), array([ 0.56410253, -0.3076923 ,  0.2051282 , -0.5641026 ], dtype=float32), array([ 0.53846145, -0.25641024,  0.23076928, -0.5641026 ], dtype=float32), array([ 0.6153846 , -0.3076923 ,  0.4102564 , -0.48717952], dtype=float32), array([ 0.8205128 , -0.25641024,  0.46153855, -0.61538464], dtype=float32), array([ 0.8717948 , -0.3076923 ,  0.53846145, -0.53846157], dtype=float32), array([ 1.        , -0.05128205,  0.6153846 , -0.51282054], dtype=float32), array([ 0.6153846 , -0.3076923 ,  0.4102564 , -0.46153843], dtype=float32), array([ 0.5897436 , -0.3076923 ,  0.2820512 , -0.64102566], dtype=float32), array([ 0.53846145, -0.3589744 ,  0.4102564 , -0.6666667 ], dtype=float32), array([ 0.94871783, -0.25641024,  0.53846145, -0.4358974 ], dtype=float32), array([ 0.5897436 , -0.15384614,  0.4102564 , -0.4102564 ], dtype=float32), array([ 0.6153846 , -0.23076928,  0.38461542, -0.5641026 ], dtype=float32), array([ 0.5128205 , -0.25641024,  0.2051282 , -0.5641026 ], dtype=float32), array([ 0.74358976, -0.23076928,  0.35897434, -0.48717952], dtype=float32), array([ 0.6923076 , -0.23076928,  0.4102564 , -0.4102564 ], dtype=float32), array([ 0.74358976, -0.23076928,  0.2820512 , -0.4358974 ], dtype=float32), array([ 0.46153855, -0.3333333 ,  0.2820512 , -0.53846157], dtype=float32), array([ 0.7179488 , -0.2051282 ,  0.48717952, -0.4358974 ], dtype=float32), array([ 0.6923076 , -0.17948717,  0.43589735, -0.38461536], dtype=float32), array([ 0.6923076 , -0.25641024,  0.3076923 , -0.4358974 ], dtype=float32), array([ 0.5897436 , -0.38461536,  0.25641024, -0.53846157], dtype=float32), array([ 0.64102566, -0.25641024,  0.3076923 , -0.51282054], dtype=float32), array([ 0.56410253, -0.15384614,  0.35897434, -0.4358974 ], dtype=float32), array([ 0.48717952, -0.25641024,  0.2820512 , -0.5641026 ], dtype=float32)], 'Iris-versicolor': [array([ 0.7692307 , -0.2051282 ,  0.17948711, -0.6666667 ], dtype=float32), array([ 0.6153846 , -0.2051282 ,  0.12820518, -0.64102566], dtype=float32), array([ 0.74358976, -0.23076928,  0.23076928, -0.64102566], dtype=float32), array([ 0.38461542, -0.4358974 ,  0.        , -0.6923077 ], dtype=float32), array([ 0.64102566, -0.3076923 ,  0.15384614, -0.64102566], dtype=float32), array([ 0.43589735, -0.3076923 ,  0.12820518, -0.6923077 ], dtype=float32), array([ 0.5897436 , -0.17948717,  0.17948711, -0.61538464], dtype=float32), array([ 0.23076928, -0.4102564 , -0.17948717, -0.7692308 ], dtype=float32), array([ 0.6666666 , -0.28205127,  0.15384614, -0.6923077 ], dtype=float32), array([ 0.3076923 , -0.3333333 , -0.02564102, -0.6666667 ], dtype=float32), array([ 0.25641024, -0.51282054, -0.12820512, -0.7692308 ], dtype=float32), array([ 0.48717952, -0.25641024,  0.05128205, -0.64102566], dtype=float32), array([ 0.5128205 , -0.46153843,  0.        , -0.7692308 ], dtype=float32), array([ 0.53846145, -0.28205127,  0.17948711, -0.6666667 ], dtype=float32), array([ 0.4102564 , -0.28205127, -0.1025641 , -0.6923077 ], dtype=float32), array([ 0.6923076 , -0.23076928,  0.1025641 , -0.6666667 ], dtype=float32), array([ 0.4102564 , -0.25641024,  0.12820518, -0.64102566], dtype=float32), array([ 0.46153855, -0.3333333 ,  0.02564096, -0.7692308 ], dtype=float32), array([ 0.56410253, -0.46153843,  0.12820518, -0.64102566], dtype=float32), array([ 0.4102564 , -0.38461536, -0.02564102, -0.74358976], dtype=float32), array([ 0.48717952, -0.2051282 ,  0.2051282 , -0.5641026 ], dtype=float32), array([ 0.53846145, -0.3076923 ,  0.        , -0.6923077 ], dtype=float32), array([ 0.5897436 , -0.38461536,  0.23076928, -0.64102566], dtype=float32), array([ 0.53846145, -0.3076923 ,  0.17948711, -0.7179487 ], dtype=float32), array([ 0.6153846 , -0.28205127,  0.07692313, -0.6923077 ], dtype=float32), array([ 0.6666666 , -0.25641024,  0.1025641 , -0.6666667 ], dtype=float32), array([ 0.7179488, -0.3076923,  0.2051282, -0.6666667], dtype=float32), array([ 0.6923076 , -0.25641024,  0.25641024, -0.5897436 ], dtype=float32), array([ 0.5128205 , -0.28205127,  0.12820518, -0.64102566], dtype=float32), array([ 0.43589735, -0.3589744 , -0.12820512, -0.7692308 ], dtype=float32), array([ 0.38461542, -0.4102564 , -0.05128205, -0.74358976], dtype=float32), array([ 0.38461542, -0.4102564 , -0.07692307, -0.7692308 ], dtype=float32), array([ 0.46153855, -0.3333333 , -0.02564102, -0.7179487 ], dtype=float32), array([ 0.5128205 , -0.3333333 ,  0.2820512 , -0.61538464], dtype=float32), array([ 0.35897434, -0.25641024,  0.12820518, -0.64102566], dtype=float32), array([ 0.5128205 , -0.15384614,  0.12820518, -0.61538464], dtype=float32), array([ 0.6923076 , -0.23076928,  0.17948711, -0.64102566], dtype=float32), array([ 0.5897436, -0.4358974,  0.1025641, -0.6923077], dtype=float32), array([ 0.4102564 , -0.25641024,  0.02564096, -0.6923077 ], dtype=float32), array([ 0.38461542, -0.38461536,  0.        , -0.6923077 ], dtype=float32), array([ 0.38461542, -0.3589744 ,  0.1025641 , -0.7179487 ], dtype=float32), array([ 0.53846145, -0.25641024,  0.15384614, -0.6666667 ], dtype=float32), array([ 0.46153855, -0.3589744 ,  0.        , -0.7179487 ], dtype=float32), array([ 0.25641024, -0.4358974 , -0.17948717, -0.7692308 ], dtype=float32), array([ 0.4102564 , -0.3333333 ,  0.05128205, -0.6923077 ], dtype=float32), array([ 0.43589735, -0.25641024,  0.05128205, -0.7179487 ], dtype=float32), array([ 0.43589735, -0.28205127,  0.05128205, -0.6923077 ], dtype=float32), array([ 0.56410253, -0.28205127,  0.07692313, -0.6923077 ], dtype=float32), array([ 0.2820512 , -0.38461536, -0.25641024, -0.74358976], dtype=float32), array([ 0.43589735, -0.3076923 ,  0.02564096, -0.6923077 ], dtype=float32)], 'Iris-setosa': [array([ 0.2820512 , -0.12820512, -0.6666667 , -0.974359  ], dtype=float32), array([ 0.23076928, -0.25641024, -0.6666667 , -0.974359  ], dtype=float32), array([ 0.17948711, -0.2051282 , -0.6923077 , -0.974359  ], dtype=float32), array([ 0.15384614, -0.23076928, -0.64102566, -0.974359  ], dtype=float32), array([ 0.25641024, -0.1025641 , -0.6666667 , -0.974359  ], dtype=float32), array([ 0.35897434, -0.02564102, -0.5897436 , -0.9230769 ], dtype=float32), array([ 0.15384614, -0.15384614, -0.6666667 , -0.94871795], dtype=float32), array([ 0.25641024, -0.15384614, -0.64102566, -0.974359  ], dtype=float32), array([ 0.1025641 , -0.28205127, -0.6666667 , -0.974359  ], dtype=float32), array([ 0.23076928, -0.23076928, -0.64102566, -1.        ], dtype=float32), array([ 0.35897434, -0.07692307, -0.64102566, -0.974359  ], dtype=float32), array([ 0.2051282 , -0.15384614, -0.61538464, -0.974359  ], dtype=float32), array([ 0.2051282 , -0.25641024, -0.6666667 , -1.        ], dtype=float32), array([ 0.07692313, -0.25641024, -0.74358976, -1.        ], dtype=float32), array([ 0.46153855,  0.        , -0.7179487 , -0.974359  ], dtype=float32), array([ 0.43589735,  0.1025641 , -0.64102566, -0.9230769 ], dtype=float32), array([ 0.35897434, -0.02564102, -0.6923077 , -0.9230769 ], dtype=float32), array([ 0.2820512 , -0.12820512, -0.6666667 , -0.94871795], dtype=float32), array([ 0.43589735, -0.05128205, -0.5897436 , -0.94871795], dtype=float32), array([ 0.2820512 , -0.05128205, -0.64102566, -0.94871795], dtype=float32), array([ 0.35897434, -0.15384614, -0.5897436 , -0.974359  ], dtype=float32), array([ 0.2820512 , -0.07692307, -0.64102566, -0.9230769 ], dtype=float32), array([ 0.15384614, -0.1025641 , -0.7692308 , -0.974359  ], dtype=float32), array([ 0.2820512 , -0.17948717, -0.5897436 , -0.8974359 ], dtype=float32), array([ 0.2051282 , -0.15384614, -0.53846157, -0.974359  ], dtype=float32), array([ 0.25641024, -0.25641024, -0.61538464, -0.974359  ], dtype=float32), array([ 0.25641024, -0.15384614, -0.61538464, -0.9230769 ], dtype=float32), array([ 0.3076923 , -0.12820512, -0.64102566, -0.974359  ], dtype=float32), array([ 0.3076923 , -0.15384614, -0.6666667 , -0.974359  ], dtype=float32), array([ 0.17948711, -0.2051282 , -0.61538464, -0.974359  ], dtype=float32), array([ 0.2051282 , -0.23076928, -0.61538464, -0.974359  ], dtype=float32), array([ 0.35897434, -0.15384614, -0.64102566, -0.9230769 ], dtype=float32), array([ 0.3076923 ,  0.02564096, -0.64102566, -1.        ], dtype=float32), array([ 0.38461542,  0.05128205, -0.6666667 , -0.974359  ], dtype=float32), array([ 0.23076928, -0.23076928, -0.64102566, -1.        ], dtype=float32), array([ 0.25641024, -0.2051282 , -0.7179487 , -0.974359  ], dtype=float32), array([ 0.38461542, -0.12820512, -0.6923077 , -0.974359  ], dtype=float32), array([ 0.23076928, -0.23076928, -0.64102566, -1.        ], dtype=float32), array([ 0.1025641 , -0.25641024, -0.6923077 , -0.974359  ], dtype=float32), array([ 0.2820512 , -0.15384614, -0.64102566, -0.974359  ], dtype=float32), array([ 0.25641024, -0.12820512, -0.6923077 , -0.94871795], dtype=float32), array([ 0.12820518, -0.4358974 , -0.6923077 , -0.94871795], dtype=float32), array([ 0.1025641, -0.2051282, -0.6923077, -0.974359 ], dtype=float32), array([ 0.25641024, -0.12820512, -0.61538464, -0.8717949 ], dtype=float32), array([ 0.2820512 , -0.05128205, -0.53846157, -0.9230769 ], dtype=float32), array([ 0.2051282 , -0.25641024, -0.6666667 , -0.94871795], dtype=float32), array([ 0.2820512 , -0.05128205, -0.61538464, -0.974359  ], dtype=float32), array([ 0.15384614, -0.2051282 , -0.6666667 , -0.974359  ], dtype=float32), array([ 0.33333337, -0.07692307, -0.64102566, -0.974359  ], dtype=float32), array([ 0.25641024, -0.17948717, -0.6666667 , -0.974359  ], dtype=float32)]}\n",
      "{'Iris-virginica': [1, 0, 0], 'Iris-versicolor': [0, 1, 0], 'Iris-setosa': [0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "def preprocess_dataset():  \n",
    "  features, labels = assembly_dataset()\n",
    "  feature_normalization(features)  \n",
    "\n",
    "  data_dictionary = {'Iris-virginica' : [], 'Iris-versicolor': [], 'Iris-setosa': []}\n",
    "\n",
    "  one_hot_label_dictionary = {'Iris-virginica' : [1,0,0], 'Iris-versicolor': [0,1,0], 'Iris-setosa': [0,0,1]}\n",
    "\n",
    "  for t in zip(features,labels):\n",
    "    data_dictionary[t[1]].append(t[0])\n",
    "  return (data_dictionary, one_hot_label_dictionary)\n",
    "data = preprocess_dataset()\n",
    "print(data[0])\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "8b85a1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.2820512 , -0.12820512, -0.6666667 , -0.974359  ], dtype=float32),\n",
       " array([ 0.23076928, -0.25641024, -0.6666667 , -0.974359  ], dtype=float32),\n",
       " array([ 0.17948711, -0.2051282 , -0.6923077 , -0.974359  ], dtype=float32),\n",
       " array([ 0.15384614, -0.23076928, -0.64102566, -0.974359  ], dtype=float32),\n",
       " array([ 0.25641024, -0.1025641 , -0.6666667 , -0.974359  ], dtype=float32),\n",
       " array([ 0.35897434, -0.02564102, -0.5897436 , -0.9230769 ], dtype=float32),\n",
       " array([ 0.15384614, -0.15384614, -0.6666667 , -0.94871795], dtype=float32),\n",
       " array([ 0.25641024, -0.15384614, -0.64102566, -0.974359  ], dtype=float32),\n",
       " array([ 0.1025641 , -0.28205127, -0.6666667 , -0.974359  ], dtype=float32),\n",
       " array([ 0.23076928, -0.23076928, -0.64102566, -1.        ], dtype=float32),\n",
       " array([ 0.35897434, -0.07692307, -0.64102566, -0.974359  ], dtype=float32),\n",
       " array([ 0.2051282 , -0.15384614, -0.61538464, -0.974359  ], dtype=float32),\n",
       " array([ 0.2051282 , -0.25641024, -0.6666667 , -1.        ], dtype=float32),\n",
       " array([ 0.07692313, -0.25641024, -0.74358976, -1.        ], dtype=float32),\n",
       " array([ 0.46153855,  0.        , -0.7179487 , -0.974359  ], dtype=float32),\n",
       " array([ 0.43589735,  0.1025641 , -0.64102566, -0.9230769 ], dtype=float32),\n",
       " array([ 0.35897434, -0.02564102, -0.6923077 , -0.9230769 ], dtype=float32),\n",
       " array([ 0.2820512 , -0.12820512, -0.6666667 , -0.94871795], dtype=float32),\n",
       " array([ 0.43589735, -0.05128205, -0.5897436 , -0.94871795], dtype=float32),\n",
       " array([ 0.2820512 , -0.05128205, -0.64102566, -0.94871795], dtype=float32),\n",
       " array([ 0.35897434, -0.15384614, -0.5897436 , -0.974359  ], dtype=float32),\n",
       " array([ 0.2820512 , -0.07692307, -0.64102566, -0.9230769 ], dtype=float32),\n",
       " array([ 0.15384614, -0.1025641 , -0.7692308 , -0.974359  ], dtype=float32),\n",
       " array([ 0.2820512 , -0.17948717, -0.5897436 , -0.8974359 ], dtype=float32),\n",
       " array([ 0.2051282 , -0.15384614, -0.53846157, -0.974359  ], dtype=float32),\n",
       " array([ 0.25641024, -0.25641024, -0.61538464, -0.974359  ], dtype=float32),\n",
       " array([ 0.25641024, -0.15384614, -0.61538464, -0.9230769 ], dtype=float32),\n",
       " array([ 0.3076923 , -0.12820512, -0.64102566, -0.974359  ], dtype=float32),\n",
       " array([ 0.3076923 , -0.15384614, -0.6666667 , -0.974359  ], dtype=float32),\n",
       " array([ 0.17948711, -0.2051282 , -0.61538464, -0.974359  ], dtype=float32),\n",
       " array([ 0.2051282 , -0.23076928, -0.61538464, -0.974359  ], dtype=float32),\n",
       " array([ 0.35897434, -0.15384614, -0.64102566, -0.9230769 ], dtype=float32),\n",
       " array([ 0.3076923 ,  0.02564096, -0.64102566, -1.        ], dtype=float32),\n",
       " array([ 0.38461542,  0.05128205, -0.6666667 , -0.974359  ], dtype=float32),\n",
       " array([ 0.23076928, -0.23076928, -0.64102566, -1.        ], dtype=float32),\n",
       " array([ 0.25641024, -0.2051282 , -0.7179487 , -0.974359  ], dtype=float32),\n",
       " array([ 0.38461542, -0.12820512, -0.6923077 , -0.974359  ], dtype=float32),\n",
       " array([ 0.23076928, -0.23076928, -0.64102566, -1.        ], dtype=float32),\n",
       " array([ 0.1025641 , -0.25641024, -0.6923077 , -0.974359  ], dtype=float32),\n",
       " array([ 0.2820512 , -0.15384614, -0.64102566, -0.974359  ], dtype=float32),\n",
       " array([ 0.25641024, -0.12820512, -0.6923077 , -0.94871795], dtype=float32),\n",
       " array([ 0.12820518, -0.4358974 , -0.6923077 , -0.94871795], dtype=float32),\n",
       " array([ 0.1025641, -0.2051282, -0.6923077, -0.974359 ], dtype=float32),\n",
       " array([ 0.25641024, -0.12820512, -0.61538464, -0.8717949 ], dtype=float32),\n",
       " array([ 0.2820512 , -0.05128205, -0.53846157, -0.9230769 ], dtype=float32),\n",
       " array([ 0.2051282 , -0.25641024, -0.6666667 , -0.94871795], dtype=float32),\n",
       " array([ 0.2820512 , -0.05128205, -0.61538464, -0.974359  ], dtype=float32),\n",
       " array([ 0.15384614, -0.2051282 , -0.6666667 , -0.974359  ], dtype=float32),\n",
       " array([ 0.33333337, -0.07692307, -0.64102566, -0.974359  ], dtype=float32),\n",
       " array([ 0.25641024, -0.17948717, -0.6666667 , -0.974359  ], dtype=float32)]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['Iris-setosa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "82384b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[  5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "  Test:  index=[  0   1   2   3   4  50  51  52  53  54 100 101 102 103 104]\n",
      "Fold 1:\n",
      "  Train: index=[  0   1   2   3   4  10  11  12  13  14  15  16  17  18  19  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "  Test:  index=[  5   6   7   8   9  55  56  57  58  59 105 106 107 108 109]\n",
      "Fold 2:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  15  16  17  18  19  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "  Test:  index=[ 10  11  12  13  14  60  61  62  63  64 110 111 112 113 114]\n",
      "Fold 3:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "  Test:  index=[ 15  16  17  18  19  65  66  67  68  69 115 116 117 118 119]\n",
      "Fold 4:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "  Test:  index=[ 20  21  22  23  24  70  71  72  73  74 120 121 122 123 124]\n",
      "Fold 5:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  30  31  32  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "  Test:  index=[ 25  26  27  28  29  75  76  77  78  79 125 126 127 128 129]\n",
      "Fold 6:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "  Test:  index=[ 30  31  32  33  34  80  81  82  83  84 130 131 132 133 134]\n",
      "Fold 7:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "  Test:  index=[ 35  36  37  38  39  85  86  87  88  89 135 136 137 138 139]\n",
      "Fold 8:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 145 146 147 148 149]\n",
      "  Test:  index=[ 40  41  42  43  44  90  91  92  93  94 140 141 142 143 144]\n",
      "Fold 9:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      " 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144]\n",
      "  Test:  index=[ 45  46  47  48  49  95  96  97  98  99 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    " # stratified random sampling\n",
    "labels = list(data[1].keys())\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "  for x_sample in data[0][labels[i]]:\n",
    "    X.append(x_sample)\n",
    "    y.append(i)\n",
    "    \n",
    "skf = StratifiedKFold(n_splits=10) # shuffle and configure seed.\n",
    "skf.get_n_splits(X, y)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "  print(f\"Fold {i}:\")\n",
    "  print(f\"  Train: index={train_index}\")\n",
    "  print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "960a9f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_index)):\n",
    "  print(y[test_index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1bf3172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w4/0dl8g1ps7db034jbgcvzs7_r0000gn/T/ipykernel_84805/4170532425.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#print(features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w4/0dl8g1ps7db034jbgcvzs7_r0000gn/T/ipykernel_84805/423137932.py\u001b[0m in \u001b[0;36mfeature_normalization\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mmax_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mmin_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "feature_normalization(features)\n",
    "#print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5912fd94",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w4/0dl8g1ps7db034jbgcvzs7_r0000gn/T/ipykernel_84805/2991436985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9cb004e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df9f7b2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "feature_normalization() missing 1 required positional argument: 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w4/0dl8g1ps7db034jbgcvzs7_r0000gn/T/ipykernel_84805/889087154.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: feature_normalization() missing 1 required positional argument: 'features'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ac7c37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Iris-virginica': [['6.3', '3.3', '6.0', '2.5'],\n",
       "  ['5.8', '2.7', '5.1', '1.9'],\n",
       "  ['7.1', '3.0', '5.9', '2.1'],\n",
       "  ['6.3', '2.9', '5.6', '1.8'],\n",
       "  ['6.5', '3.0', '5.8', '2.2'],\n",
       "  ['7.6', '3.0', '6.6', '2.1'],\n",
       "  ['4.9', '2.5', '4.5', '1.7'],\n",
       "  ['7.3', '2.9', '6.3', '1.8'],\n",
       "  ['6.7', '2.5', '5.8', '1.8'],\n",
       "  ['7.2', '3.6', '6.1', '2.5'],\n",
       "  ['6.5', '3.2', '5.1', '2.0'],\n",
       "  ['6.4', '2.7', '5.3', '1.9'],\n",
       "  ['6.8', '3.0', '5.5', '2.1'],\n",
       "  ['5.7', '2.5', '5.0', '2.0'],\n",
       "  ['5.8', '2.8', '5.1', '2.4'],\n",
       "  ['6.4', '3.2', '5.3', '2.3'],\n",
       "  ['6.5', '3.0', '5.5', '1.8'],\n",
       "  ['7.7', '3.8', '6.7', '2.2'],\n",
       "  ['7.7', '2.6', '6.9', '2.3'],\n",
       "  ['6.0', '2.2', '5.0', '1.5'],\n",
       "  ['6.9', '3.2', '5.7', '2.3'],\n",
       "  ['5.6', '2.8', '4.9', '2.0'],\n",
       "  ['7.7', '2.8', '6.7', '2.0'],\n",
       "  ['6.3', '2.7', '4.9', '1.8'],\n",
       "  ['6.7', '3.3', '5.7', '2.1'],\n",
       "  ['7.2', '3.2', '6.0', '1.8'],\n",
       "  ['6.2', '2.8', '4.8', '1.8'],\n",
       "  ['6.1', '3.0', '4.9', '1.8'],\n",
       "  ['6.4', '2.8', '5.6', '2.1'],\n",
       "  ['7.2', '3.0', '5.8', '1.6'],\n",
       "  ['7.4', '2.8', '6.1', '1.9'],\n",
       "  ['7.9', '3.8', '6.4', '2.0'],\n",
       "  ['6.4', '2.8', '5.6', '2.2'],\n",
       "  ['6.3', '2.8', '5.1', '1.5'],\n",
       "  ['6.1', '2.6', '5.6', '1.4'],\n",
       "  ['7.7', '3.0', '6.1', '2.3'],\n",
       "  ['6.3', '3.4', '5.6', '2.4'],\n",
       "  ['6.4', '3.1', '5.5', '1.8'],\n",
       "  ['6.0', '3.0', '4.8', '1.8'],\n",
       "  ['6.9', '3.1', '5.4', '2.1'],\n",
       "  ['6.7', '3.1', '5.6', '2.4'],\n",
       "  ['6.9', '3.1', '5.1', '2.3'],\n",
       "  ['5.8', '2.7', '5.1', '1.9'],\n",
       "  ['6.8', '3.2', '5.9', '2.3'],\n",
       "  ['6.7', '3.3', '5.7', '2.5'],\n",
       "  ['6.7', '3.0', '5.2', '2.3'],\n",
       "  ['6.3', '2.5', '5.0', '1.9'],\n",
       "  ['6.5', '3.0', '5.2', '2.0'],\n",
       "  ['6.2', '3.4', '5.4', '2.3'],\n",
       "  ['5.9', '3.0', '5.1', '1.8']],\n",
       " 'Iris-versicolor': [['7.0', '3.2', '4.7', '1.4'],\n",
       "  ['6.4', '3.2', '4.5', '1.5'],\n",
       "  ['6.9', '3.1', '4.9', '1.5'],\n",
       "  ['5.5', '2.3', '4.0', '1.3'],\n",
       "  ['6.5', '2.8', '4.6', '1.5'],\n",
       "  ['5.7', '2.8', '4.5', '1.3'],\n",
       "  ['6.3', '3.3', '4.7', '1.6'],\n",
       "  ['4.9', '2.4', '3.3', '1.0'],\n",
       "  ['6.6', '2.9', '4.6', '1.3'],\n",
       "  ['5.2', '2.7', '3.9', '1.4'],\n",
       "  ['5.0', '2.0', '3.5', '1.0'],\n",
       "  ['5.9', '3.0', '4.2', '1.5'],\n",
       "  ['6.0', '2.2', '4.0', '1.0'],\n",
       "  ['6.1', '2.9', '4.7', '1.4'],\n",
       "  ['5.6', '2.9', '3.6', '1.3'],\n",
       "  ['6.7', '3.1', '4.4', '1.4'],\n",
       "  ['5.6', '3.0', '4.5', '1.5'],\n",
       "  ['5.8', '2.7', '4.1', '1.0'],\n",
       "  ['6.2', '2.2', '4.5', '1.5'],\n",
       "  ['5.6', '2.5', '3.9', '1.1'],\n",
       "  ['5.9', '3.2', '4.8', '1.8'],\n",
       "  ['6.1', '2.8', '4.0', '1.3'],\n",
       "  ['6.3', '2.5', '4.9', '1.5'],\n",
       "  ['6.1', '2.8', '4.7', '1.2'],\n",
       "  ['6.4', '2.9', '4.3', '1.3'],\n",
       "  ['6.6', '3.0', '4.4', '1.4'],\n",
       "  ['6.8', '2.8', '4.8', '1.4'],\n",
       "  ['6.7', '3.0', '5.0', '1.7'],\n",
       "  ['6.0', '2.9', '4.5', '1.5'],\n",
       "  ['5.7', '2.6', '3.5', '1.0'],\n",
       "  ['5.5', '2.4', '3.8', '1.1'],\n",
       "  ['5.5', '2.4', '3.7', '1.0'],\n",
       "  ['5.8', '2.7', '3.9', '1.2'],\n",
       "  ['6.0', '2.7', '5.1', '1.6'],\n",
       "  ['5.4', '3.0', '4.5', '1.5'],\n",
       "  ['6.0', '3.4', '4.5', '1.6'],\n",
       "  ['6.7', '3.1', '4.7', '1.5'],\n",
       "  ['6.3', '2.3', '4.4', '1.3'],\n",
       "  ['5.6', '3.0', '4.1', '1.3'],\n",
       "  ['5.5', '2.5', '4.0', '1.3'],\n",
       "  ['5.5', '2.6', '4.4', '1.2'],\n",
       "  ['6.1', '3.0', '4.6', '1.4'],\n",
       "  ['5.8', '2.6', '4.0', '1.2'],\n",
       "  ['5.0', '2.3', '3.3', '1.0'],\n",
       "  ['5.6', '2.7', '4.2', '1.3'],\n",
       "  ['5.7', '3.0', '4.2', '1.2'],\n",
       "  ['5.7', '2.9', '4.2', '1.3'],\n",
       "  ['6.2', '2.9', '4.3', '1.3'],\n",
       "  ['5.1', '2.5', '3.0', '1.1'],\n",
       "  ['5.7', '2.8', '4.1', '1.3']],\n",
       " 'Iris-setosa': [['5.1', '3.5', '1.4', '0.2'],\n",
       "  ['4.9', '3.0', '1.4', '0.2'],\n",
       "  ['4.7', '3.2', '1.3', '0.2'],\n",
       "  ['4.6', '3.1', '1.5', '0.2'],\n",
       "  ['5.0', '3.6', '1.4', '0.2'],\n",
       "  ['5.4', '3.9', '1.7', '0.4'],\n",
       "  ['4.6', '3.4', '1.4', '0.3'],\n",
       "  ['5.0', '3.4', '1.5', '0.2'],\n",
       "  ['4.4', '2.9', '1.4', '0.2'],\n",
       "  ['4.9', '3.1', '1.5', '0.1'],\n",
       "  ['5.4', '3.7', '1.5', '0.2'],\n",
       "  ['4.8', '3.4', '1.6', '0.2'],\n",
       "  ['4.8', '3.0', '1.4', '0.1'],\n",
       "  ['4.3', '3.0', '1.1', '0.1'],\n",
       "  ['5.8', '4.0', '1.2', '0.2'],\n",
       "  ['5.7', '4.4', '1.5', '0.4'],\n",
       "  ['5.4', '3.9', '1.3', '0.4'],\n",
       "  ['5.1', '3.5', '1.4', '0.3'],\n",
       "  ['5.7', '3.8', '1.7', '0.3'],\n",
       "  ['5.1', '3.8', '1.5', '0.3'],\n",
       "  ['5.4', '3.4', '1.7', '0.2'],\n",
       "  ['5.1', '3.7', '1.5', '0.4'],\n",
       "  ['4.6', '3.6', '1.0', '0.2'],\n",
       "  ['5.1', '3.3', '1.7', '0.5'],\n",
       "  ['4.8', '3.4', '1.9', '0.2'],\n",
       "  ['5.0', '3.0', '1.6', '0.2'],\n",
       "  ['5.0', '3.4', '1.6', '0.4'],\n",
       "  ['5.2', '3.5', '1.5', '0.2'],\n",
       "  ['5.2', '3.4', '1.4', '0.2'],\n",
       "  ['4.7', '3.2', '1.6', '0.2'],\n",
       "  ['4.8', '3.1', '1.6', '0.2'],\n",
       "  ['5.4', '3.4', '1.5', '0.4'],\n",
       "  ['5.2', '4.1', '1.5', '0.1'],\n",
       "  ['5.5', '4.2', '1.4', '0.2'],\n",
       "  ['4.9', '3.1', '1.5', '0.1'],\n",
       "  ['5.0', '3.2', '1.2', '0.2'],\n",
       "  ['5.5', '3.5', '1.3', '0.2'],\n",
       "  ['4.9', '3.1', '1.5', '0.1'],\n",
       "  ['4.4', '3.0', '1.3', '0.2'],\n",
       "  ['5.1', '3.4', '1.5', '0.2'],\n",
       "  ['5.0', '3.5', '1.3', '0.3'],\n",
       "  ['4.5', '2.3', '1.3', '0.3'],\n",
       "  ['4.4', '3.2', '1.3', '0.2'],\n",
       "  ['5.0', '3.5', '1.6', '0.6'],\n",
       "  ['5.1', '3.8', '1.9', '0.4'],\n",
       "  ['4.8', '3.0', '1.4', '0.3'],\n",
       "  ['5.1', '3.8', '1.6', '0.2'],\n",
       "  ['4.6', '3.2', '1.4', '0.2'],\n",
       "  ['5.3', '3.7', '1.5', '0.2'],\n",
       "  ['5.0', '3.3', '1.4', '0.2']]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a49ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
